{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week4_statistics_in_Python.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/connorgrannis/nch_python_workshop/blob/master/Week4_statistics_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcVPfGYcyRVI",
        "colab_type": "text"
      },
      "source": [
        "#__DISCLAIMER__\n",
        "We are not the most equipped to go through an in depth explanation of all the statistical methods and models we will be presenting in this workshop. We will try and cover the basics, but this week's workshop is designed in mind to present to you the \"toolbox\" and not necessarily best use cases for each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEJr9ruv-7z0",
        "colab_type": "text"
      },
      "source": [
        "#__Statistics in Python__\n",
        "There are a number of ways to go about planning and creating different statistical models using Python. From a simple T-test to larger and more complex models, much of what you will ever need to do (statistically) in Python is handled in just two major libraries: Scipy and Statsmodels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uo5hp5s_pST",
        "colab_type": "text"
      },
      "source": [
        "#__Scipy__\n",
        "Scipy is an enormous python library similar to the likes of Numpy, and provides a huge array of tools for scientific computing. This ranges from things like linear algebra to image manipulation, and each of Scipy's specialties are broken down and contained within sub-branches contained within the main package. The one we'll be focusing on is Scipy.stats. \n",
        "\n",
        "[link to scipy main page]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIfTkJWMAz5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfwjN4X6-6p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQTcwD2P_oG0",
        "colab_type": "text"
      },
      "source": [
        "#__Statsmodels__\n",
        "Statsmodels is built off scipy.stats, but contains more specific statistical models using a formula framework similar to something you might find in R. Statsmodels was also built to work very well with Pandas dataframes. \n",
        "\n",
        "[link to statsmodel main page]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICSxxzfuBT9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install statsmodels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKof9sriBXVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.api as sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOWh-7NwBcoV",
        "colab_type": "text"
      },
      "source": [
        "#__Other Packages__\n",
        "\n",
        "While the two libraries above will cover the bulk, if not all, of all your statistical needs there are several other packages that you may find useful. One we will talk use for some things in this week's workshop is Pingouin. Pingouin is similar to the previous packages, though slightly more limited in its scope, and offers several useful statistical models that rival in utitlity some of the pre-established versions in scipy and statmodels. One of the great things about Pingouin is how much more approachable it is than some of the previous mentioned packages. There are likely several other statistical packages in Python, but these are the three we'll be using today.\n",
        "\n",
        "[pingouin link]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIhWOLy5BcQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pingouin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDZFv8AkBbfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pingouin as pg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee8otjxH6BkS",
        "colab_type": "text"
      },
      "source": [
        "#__t-tests__\n",
        "\n",
        "Lets start with a simple t-test. To begin we'll load back in the titanic dataset into a pandas dataframe just like we've been doing in previous sections.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lcISnRz6AzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "titanic = pd.read_csv('https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRliWsNAAt7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanic.head() #to take a quick look at the data we're working with"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE06trAhAu2-",
        "colab_type": "text"
      },
      "source": [
        "So looking at the data above, let's do a basic 2-sided t-test to see if age differs between those who survived or didn't.\n",
        "\n",
        "We'll use statsmodels and pingouin to do the same test with the same data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYygSyCSHl6s",
        "colab_type": "text"
      },
      "source": [
        "Starting with Scipy. \n",
        "\n",
        "Here's the function we'll use: [documention](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gyiwqtwA0_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## using Scipy.stats\n",
        "\n",
        "from scipy import stats   # we only need the stats portion of scipy\n",
        "\n",
        "survived = titanic['Survived'] == 1\n",
        "died = titanic['Survived'] == 0\n",
        "\n",
        "t, p = stats.ttest_ind(titanic[survived]['Age'], titanic[died]['Age'], nan_policy='omit')\n",
        "\n",
        "print(f't-stat is: {t}\\np-value is: {p}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOCTfIstc-_7",
        "colab_type": "text"
      },
      "source": [
        "Let's take a closer look at what we did here.\n",
        "\n",
        "First we imported the stats module from scipy: `from scipy import stats`\n",
        "\n",
        "The next two lines:\n",
        "```\n",
        "survived = titanic['Survived'] == 1\n",
        "died = titanic['Survived'] == 0\n",
        "```\n",
        "create a boolean 'filter' where the row is `True` if the value in the 'Survived' column matches the condition (==1 for survived, and ==0 for died). \n",
        "\n",
        "We can now use this filter on our main dataframe to split our data into two groups, those who survived and those who did not.\n",
        "\n",
        "Now we have everything prepared to conduct our t-test using `stats.ttest_ind`.\n",
        "We specify our two population arrays `titanic[survived]['Age']` for the ages of those that survived, and `titanic[died]['Age']` for those that did not. One final note is the last argument of the function: `nan_policy='omit'`, this is how we are asking the function to handle missing data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf9PF_0qFVN0",
        "colab_type": "text"
      },
      "source": [
        "Now lets run the exact same test using statsmodels. It's very similar to how we handled it with Scipy.\n",
        "\n",
        "[Documentation on the function](https://www.statsmodels.org/stable/generated/statsmodels.stats.weightstats.ttest_ind.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lGH2muoJ-sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t-test using statsmodels\n",
        "import statsmodels.stats as sms\n",
        "\n",
        "survived = titanic['Survived'] == 1\n",
        "died = titanic['Survived'] == 0\n",
        "\n",
        "t, p, df = sms.weightstats.ttest_ind(titanic[survived]['Age'], titanic[died]['Age'])\n",
        "\n",
        "print(f'''\n",
        "t-stat is: {t}\n",
        "p-value is: {p}\n",
        "degrees of freedom: {df}\n",
        "''')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUMIOFb8Nxmw",
        "colab_type": "text"
      },
      "source": [
        "Well that didn't work. That's because the statsmodels' t-test doesn't have a way to handle missing data at the t-test level. we'll need to handle it at the dataframe level instead. We can use the pandas method df.dropna() to do that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A7_0lCxA5_G",
        "colab_type": "text"
      },
      "source": [
        "### Handling Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RtLEr8SNnEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanic_no_missing = titanic.dropna()\n",
        "\n",
        "# This removes the entire row containing missing data in ANY column. if we want to only remove rows with missing data in the 'Age' column\n",
        "titanic_no_age_missing = titanic.dropna(subset=['Age'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNiT81tvAsdz",
        "colab_type": "text"
      },
      "source": [
        "The subset can be multiple columns eg. subset=['Age', 'Fare'], and will remove rows where any missing data is present in either row. Note how I'm not replacing the original Titanic dataframe and instead creating new ones from the modified original. If you want, you could modify the original by adding in the inplace=True argument to the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kww6fc-QBD2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "survived = titanic_no_age_missing['Survived'] == 1\n",
        "died = titanic_no_age_missing['Survived'] == 0\n",
        "\n",
        "t, p, df = sms.weightstats.ttest_ind(titanic_no_age_missing[survived]['Age'], titanic_no_age_missing[died]['Age'])\n",
        "\n",
        "print(f'''\n",
        "t-stat is: {t}\n",
        "p-value is: {p}\n",
        "degrees of freedom: {df}\n",
        "''')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTBmaIM_OhUT",
        "colab_type": "text"
      },
      "source": [
        "Lastly lets try the exact same thing with Pingouin. \n",
        "\n",
        "[Documentation](https://pingouin-stats.org/generated/pingouin.ttest.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Vg_8Hn5mg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t-test using pingouin\n",
        "# setup similar to statmodels\n",
        "\n",
        "titanic_no_age_missing = titanic.dropna(subset=['Age'])\n",
        "\n",
        "survived = titanic_no_age_missing['Survived'] == 1\n",
        "died = titanic_no_age_missing['Survived'] == 0\n",
        "\n",
        "# we set correction to False as for simplicity's sake in this example we assume the variance is the same between both groups.\n",
        "results = pg.ttest(titanic_no_age_missing[survived]['Age'], titanic_no_age_missing[died]['Age'], correction=False)\n",
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IE8PAbN5q63",
        "colab_type": "text"
      },
      "source": [
        "So we used three different statistical packages in python to run the same t-test. Scipy only gave us the t-stat and p-value, while statsmodels additionally gave us the degrees of freedom. Pingouin was the most exhaustive and returned a pandas dataframe containing a number of relevant results pertaining to the t-test. Overall most of this comes down to preference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ87vLUpRU3Y",
        "colab_type": "text"
      },
      "source": [
        "### Your Turn\n",
        "\n",
        "Now try and run t-tests using each of the three packages to see if the passanger's `Fare` differed between `Sex`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeaJ3d_bR4H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Scipy.stats\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twjCnXK6R32x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using statsmodels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBksGlI_R3jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Pingouin \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw6rZ3I7fOKN",
        "colab_type": "text"
      },
      "source": [
        "#__ANOVA__\n",
        "\n",
        "Similar to t-tests, all the main statistical packages in Python contain their own versions of ANOVA, we won't go into detail on how to perform them with each statistical package and instead just show you one way of doing it. Though we will provode the documentation for the other methods.\n",
        "\n",
        "[Scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html)\n",
        "\n",
        "[Statsmodels](https://www.statsmodels.org/devel/anova.html)\n",
        "\n",
        "[Pingouin](https://pingouin-stats.org/generated/pingouin.anova.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3FIO0baC894",
        "colab_type": "text"
      },
      "source": [
        "Let's see if `Age` differs by the passenger's class (`Pclass`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOREzvKZOcfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using Scipy\n",
        "\n",
        "# drop nans\n",
        "titanic_nomiss_age = titanic.dropna(subset=['Age'])\n",
        "\n",
        "# now filtering dataframe by ticket class\n",
        "firstclass = titanic_nomiss_age['Pclass'] == 1\n",
        "secondclass = titanic_nomiss_age['Pclass'] == 2\n",
        "thirdclass = titanic_nomiss_age['Pclass'] == 3\n",
        "\n",
        "# finally the ANOVA\n",
        "f, p = stats.f_oneway(\n",
        "    titanic_nomiss_age[firstclass]['Age'], \n",
        "    titanic_nomiss_age[secondclass]['Age'], \n",
        "    titanic_nomiss_age[thirdclass]['Age'])\n",
        "\n",
        "print(f\"\"\"\n",
        "F-value: {f}\n",
        "p-value: {p}\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09vpoT-Dl04h",
        "colab_type": "text"
      },
      "source": [
        "So we have found that there is a significant difference of age between the ticket classes but, as I'm sure many of you know, generally we now want to see specifically what classes are different from one another. So we need to perform post-hoc tests. One of the common post-hoc tests is Tukeys HSD and is easily performed using the statsmodels library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2jttN7El0d1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from statsmodels.stats.multicomp import MultiComparison\n",
        "\n",
        "mc = MultiComparison(titanic_nomiss_age['Age'], titanic_nomiss_age['Pclass'])\n",
        "result = mc.tukeyhsd(alpha=0.05)  # alpha is set to 0.05 by default\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaBwsRWzpU-0",
        "colab_type": "text"
      },
      "source": [
        "First we use the [multicomparison](https://www.statsmodels.org/stable/generated/statsmodels.sandbox.stats.multicomp.MultiComparison.html) tool, which sets the data up for multiple comparisons, and had several methods (shown at the bottom of the linked page) for different multiple comparison tests. In our case we used the [tukeyshsd](https://www.statsmodels.org/stable/generated/statsmodels.sandbox.stats.multicomp.MultiComparison.tukeyhsd.html#statsmodels.sandbox.stats.multicomp.MultiComparison.tukeyhsd) method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1WHHU-Gt1_M",
        "colab_type": "text"
      },
      "source": [
        "##Your Turn\n",
        "\n",
        "Try creating another ANOVA model below to see if `Fare` differs depending on where the passengers `Embarked` from. Then (even if F of group isn't significant! This is just practice) run post-hoc tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHsUorG8Dkwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzgpgshPtOWA",
        "colab_type": "text"
      },
      "source": [
        "#__Statsmodels formulas__\n",
        "Before moving into some of the slightly more complicated modeling, this is a good time to introduce one of the more powerful tools contained within the statsmodels package. For those of you that are familiar with R this will come easily (as it's based directly off of it!)\n",
        "\n",
        "Statsmodels has the ability to use \"formulas\" to set up statistical models easily and efficiently, and the formula syntax is based off the R programming language. For a detailed explanation please take a look [here](https://patsy.readthedocs.io/en/latest/formulas.html#the-formula-language). \n",
        "\n",
        "Briefly, models can be set up using a notation like: `'y ~ x'` where `~` separates the sides of the equation this would look at how `y` is affected by `x`. By using the `+` operator you can add to one side of the equation: `'y ~ x + z'` which would look at how `y` is affected by `x` and `z`. \n",
        "\n",
        "To take this one step further we have the operators `:` and `*`.\n",
        "\n",
        "`:` is a way of modeling an interaction effect: `y ~ x:z` looks at how `y` is affected by the interaction of `x` and `z`. The `*` operator is a shorthand for a full factorial model: `y ~ x*z` is the same as `y ~ x + z + x:z`.\n",
        "\n",
        "The link provided above will go into more detail explaining the forumla syntax and how to use it, there are a few more operators we didn't go through here so I would recommend giving the page a read through."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SN9pg5rCacT",
        "colab_type": "text"
      },
      "source": [
        "#__MANOVA__\n",
        "\n",
        "The easiest way of performing a MANOVA in python is to use the previously mentioned statsmodels formula syntax coupled with the statsmodels MANOVA tool.\n",
        "\n",
        "Lets try it below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_8r-ucXRtn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.multivariate.manova import MANOVA\n",
        "\n",
        "M = MANOVA.from_formula('Age + Fare ~ Pclass', data=titanic_nomiss_age)\n",
        "\n",
        "print(M.mv_test())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxlg2oWX7ogg",
        "colab_type": "text"
      },
      "source": [
        "#__Chi-Squared testing__\n",
        "\n",
        "Another relatively common statistical model that is easy to implement in Python is the Chi-Squared test. The tool we will use for this is contained in the `scipy.stats` package: `chi2_contingency()`, documented [here](https://scipy.github.io/devdocs/generated/scipy.stats.chi2_contingency.html). All we need to do is format our data in the correct way to create a crosstab table. Pandas makes this very easy with their `crosstab()` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html)).\n",
        "\n",
        "Lets try it below to look at survival rates based on sex. Our null hypotheses is that equal amounts of men and women should be present in both categories of `Survived`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgBr8Uqg7pDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the crosstab\n",
        "ct = pd.crosstab(titanic['Sex'], titanic['Survived'])\n",
        "ct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIvZmFF4-U_L",
        "colab_type": "text"
      },
      "source": [
        "Now we have our counts let's run the test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Olg44rW_Wx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stat, p, dof, expected = stats.chi2_contingency(ct)\n",
        "\n",
        "print(f\"\"\" \n",
        "stat: {stat} \n",
        "p: {p} \n",
        "dof: {dof}\n",
        "expected:\n",
        "{expected}\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZJoRHTrAzxZ",
        "colab_type": "text"
      },
      "source": [
        "using those results we can safely reject our null hypthesis. \n",
        "\n",
        "You can use pingouin to run a chi-squared as well, taking out the step of creating the crosstab. Here's a link to the [pingouin version](https://pingouin-stats.org/generated/pingouin.chi2_independence.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M8tGueG5vYZ",
        "colab_type": "text"
      },
      "source": [
        "#__Linear regression__\n",
        "\n",
        "Moving into linear regression, statsmodels again makes this relatively straightforward to perform using the formula syntax. Lets take a look at the example below looking at how `Fare` is affected by `Age`. We will be using an ordinary least squares (OLS) model through the `statsmodels.formula.OLS()` function, documented [here](https://www.statsmodels.org/devel/generated/statsmodels.regression.linear_model.OLS.html). \n",
        "\n",
        "Though we are using OLS here, statsmodels also provides other linear regression models: GLS, WLS, and GLM among others (and the parameters are all very similar to the OLS model we'll be describing here) so don't feel constrained by just using the OLS model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iHwdNo65p68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# lets first drop any missing values in our variables of interest.\n",
        "titanic_nomiss_age_fare = titanic.dropna(subset=['Fare', 'Age'])\n",
        "\n",
        "# now create the model.\n",
        "model = smf.ols(formula='Fare ~ Age', data=titanic_nomiss_age_fare)\n",
        "\n",
        "# finally we fit the model.\n",
        "results = model.fit()\n",
        "\n",
        "# and take a look at the result.\n",
        "print(results.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnF-zjI-bQGd",
        "colab_type": "text"
      },
      "source": [
        "Ok that's interesting, how about we now look into additional variables. Lets add in `Sex` to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ5Aks1vbGPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# additionally dropping missing sex values\n",
        "titanic_nomiss_age_fare_sex = titanic.dropna(subset=['Age', 'Sex', 'Fare'])\n",
        "\n",
        "# creating new model with sex included\n",
        "newmodel = smf.ols(formula='Fare ~ Age + C(Sex)', data=titanic_nomiss_age_fare_sex)\n",
        "\n",
        "# fitting model\n",
        "results = newmodel.fit()\n",
        "\n",
        "print(results.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwvUsrqWcu29",
        "colab_type": "text"
      },
      "source": [
        "So here we added in sex to the model, notice in the formula we surrounded it with `C()`, while in this case this may not be strictly needed, it forces statsmodels to view that variable as categorical. To finish this off let's run a model containing the interaction of `Age` and `Sex` and then run a full factorial model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_JO1CuUdI9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# just the interaction\n",
        "interaction= smf.ols(formula='Fare ~ Age:C(Sex)', data=titanic_nomiss_age_fare_sex)\n",
        "\n",
        "# fitting model\n",
        "results = interaction.fit()\n",
        "\n",
        "print(results.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV-i94UJdYCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# full factorial\n",
        "\n",
        "fullfactorial = smf.ols(formula='Fare ~ Age*C(Sex)', data=titanic_nomiss_age_fare_sex)\n",
        "\n",
        "# fitting model\n",
        "results = fullfactorial.fit()\n",
        "\n",
        "print(results.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO4EfoMjcM_X",
        "colab_type": "text"
      },
      "source": [
        "#__Conclusion__\n",
        "\n",
        "This was really only just a shallow dip to introduce the tools available when it comes to statistical computing with Python. There's far more than what we've presented here, and we encourage you to go out and seek new resources and tools as this really just scratches the surface. \n",
        "\n",
        "Again as always please contact us if you have any questions!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KXVsW9nJ6lu",
        "colab_type": "text"
      },
      "source": [
        "# Exercise #1\n",
        "Go back to the annotated graphs from last week and replace `p-value = ??` with the actual p-value, rounded to 3 decimal points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp4DSVDdJ5_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVw8dogYKMlv",
        "colab_type": "text"
      },
      "source": [
        "# Exercise #2\n",
        "We wanted to have a fun, comprehensive exercise that will use concepts from each of the weeks.  Below will be some partially completed code that examines the differences in popularity, profit, runtime, and more between Marvel and DC movies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCZ9YtocKL3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys, re    # `re` is a package that uses regex (regular expressions). We won't go into this too much, \n",
        "# but it's an efficient way to search for strings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# load the dataset\n",
        "movies = pd.read_csv('https://raw.githubusercontent.com/harshitcodes/tmdb_movie_data_analysis/master/tmdb-5000-movie-dataset/tmdb_5000_movies.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEKgebj7bH9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7-hcpQrb16f",
        "colab_type": "text"
      },
      "source": [
        "Notice how some of the cells are dictionaries instead of text. The following code will use regular expressions to extract just the information we're interested in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGkFg8UWbyn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genres = []   # empty list that we'll populate with the extracted values\n",
        "for row in range(len(movies['genres'])):\n",
        "  genre_start = [m.start()+8 for m in re.finditer('\"name\"', movies.genres[row])]    # list comprehension that finds each instance of '\"name\"' and adds 8 to get to the start of the actual value\n",
        "  genres.append(', '.join([movies.genres[row][genre_start[i]: movies.genres[row].find('}', genre_start[i])] for i in range(len(genre_start))]))\n",
        "  # that's a confusing line ^^\n",
        "  # basically, for each instance of '\"name\"' we're going to collect the text from 8 characters past '\"name\"' until the next '}' and add that value to our genres list\n",
        "  # and we're going to repeat this for each row in the dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCEPx3OPdQOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies.shape[0] == len(genres)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "220jDjmCdfc4",
        "colab_type": "text"
      },
      "source": [
        "let's do the same thing for the production companies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sprojC4BdSP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "production_companies = []\n",
        "for row in range(len(movies['production_companies'])):\n",
        "  prod_start = [m.start()+8 for m in re.finditer('\"name\"', movies.production_companies[row])]\n",
        "  production_companies.append(', '.join([movies.production_companies[row][prod_start[i]: movies.production_companies[row].find(',', prod_start[i])] for i in range(len(prod_start))]))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA90Pb6AfjHb",
        "colab_type": "text"
      },
      "source": [
        "Replace the existing `genres` and `production_companies` series with the new lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0rA3PxCfhut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wTTs6yRfyhh",
        "colab_type": "text"
      },
      "source": [
        "Make a new column in the dataframe titled `profit` and populate it with how much money each movie earned (revenue minus budget)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLE5BK36gCgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L2ytCODgDR5",
        "colab_type": "text"
      },
      "source": [
        "Filter the dataframe to only keep movies that have either `Marvel` or `DC Entertainment` listed in the production company. You can either do this at the same time, or you can make 2 new dataframes and `concatenate` them. Add a new column of either 'Marvel' or 'DC' so we can easily hue it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2ImmLlggP04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4I2HEtUkIh7",
        "colab_type": "text"
      },
      "source": [
        "Make a scatterplot of popularity by profit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRyXtTieg980",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar0mooTokNVc",
        "colab_type": "text"
      },
      "source": [
        "Add arrows pointing to the two outliers on popularity and have the title on the other end of the arrow.\n",
        "\n",
        "Hint: One way to get the names is to use `groupby` on the titles, filter by `popularity`, get the max value, and then sort the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAbv8d20iSE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0oLo2Qjzzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKPwzY_VIxh8",
        "colab_type": "text"
      },
      "source": [
        "Perform a t-test to see if popularity differs significantly by production company. Try it with and without the outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCi9CmAQFAMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvPusB14KOiX",
        "colab_type": "text"
      },
      "source": [
        "Perform a linear regression to see if `profit` is predicted by `popularity`, `runtime`, `production company`, and any interactions between them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UrTvr6LLyvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}